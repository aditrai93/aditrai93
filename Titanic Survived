import pandas as pd
import numpy as np # linear algebra
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split

titanic_train_df=pd.read_csv("C:/Users/Aditya/Downloads/train.csv")
titanic_test_df=pd.read_csv("C:/Users/Aditya/Downloads/test.csv")
X.drop(['Cabin'],axis=1,inplace=True)
X.drop(['Age'],axis=1,inplace=True)
X.drop(['Name'],axis=1,inplace=True)
y=titanic_train_df.Survived
X.drop(['PassengerId'],axis=1,inplace=True)

from sklearn.preprocessing import LabelEncoder
label_encoder=LabelEncoder()
X['Sex']=label_encoder.fit_transform(X['Sex'])

from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12,10))
cor = X.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

#Correlation with output variable
cor_target = abs(cor["Survived"])
#Selecting highly correlated features
cor_target

X.drop(['Survived'],axis=1,inplace=True)

titanic_features=["Sex"]

X_train=X[titanic_features].copy()
train_X, val_X, train_y, val_y = train_test_split(X_train, y, train_size=0.8, test_size=0.2,random_state=0)
X_test=titanic_test_df[titanic_features].copy()
replace_map = {'Sex': {'male':1,'female': 0}}
X_test_replace=X_test.copy()
X_test_replace.replace(replace_map, inplace=True)

from sklearn.ensemble import RandomForestRegressor
model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)
model_3.fit(train_X, train_y)
val_predictions = model_3.predict(val_X)
print(mean_absolute_error(val_y, val_predictions)*100)

prd=model_3.predict(X_test_replace)

output = pd.DataFrame({'PassengerId': titanic_test_df.PassengerId,
                       'Survived': prd})
output.to_csv(r'C:\Users\Aditya\Downloads\predicted6.csv', index=False)
